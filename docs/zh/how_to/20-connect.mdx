---
weight: 20
---

# 选择连接地址并配置连接方式
业务应用访问 Kafka 实例时有多种连接方式，本节描述了如何选择连接地址，通过连接地址访问到 Kafka 实例，并举例演示。

## 服务端提供的连接方式与适用场景说明

在创建 Kafka 实例时，服务端将提供多种访问链路组合，相关参数说明：

* **集群内/外访问**：应用与 Kafka 服务端是否在同一个业务集群内。
* **认证机制**：是否开启认证鉴权，以对客户端进行身份验证，认证机制支持 SCRAM-SHA-512 与 TLS 两种协议（注意：TLS 的认证机制仅支持在 TLS 加密传输的链路上开启）。
* **传输加密**：用以保障数据传输过程中的安全，采用数据加密技术，防止数据在网络传输过程中被截取或者窃听，传输加密协议通常为 TLS。

| 访问方式    | 认证机制                          | 传输加密 | 适用场景                                                                                     |
|------------|-----------------------------------|----------|----------------------------------------------------------------------------------------------|
| 集群内     | 不开启                            | 不开启   | 测试场景                                                                                     |
| 集群内     | 不开启                            | 开启     | 测试场景                                                                                     |
| 集群内     | 开启 SCRAM-SHA-512 （推荐）       | 不开启   | 访问走集群内部的网络，消息传输过程不加密，但消息收发需要鉴权。                               |
| 集群内     | 开启 SCRAM-SHA-512 或 TLS（更安全）| 开启     | 访问走集群内部的网络，消息传输过程加密，消息收发需要鉴权。（安全性更高，性能有损耗）         |
| 集群外     | 不开启                            | 不开启   | 不推荐                                                                                       |
| 集群外     | 不开启                            | 开启     | 测试场景                                                                                     |
| 集群外     | 开启 SCRAM-SHA-512                | 不开启   | 访问走集群外部网络，消息传输过程不加密                                                       |
| 集群外     | 开启 SCRAM-SHA-512 或 TLS（推荐） | 开启     | 访问走集群外部的网络，消息传输过程加密，消息收发需要鉴权。（安全性更高，性能有损耗）         |

## 客户端配置说明

客户端在进行连接时，需要根据以下信息选取合适的链路并配置相应的参数：

| 参数项             | 客户端                                                                                     |
|--------------------|------------------------------------------------------------------------------------------|
| 传输加密           | 如果客户端需要走加密通路，则需要走对应的端口，并配置 TLS 协议的证书。                       |
| 认证与鉴权         | 如果 Kafka 实例开启了鉴权认证，客户端需要配置相应协议的用户、密码或证书。                   |
| 集群内/外连接      | 应用根据位置选取所需的连接地址。                                                           |

我们以几种典型的访问链路做演示（Java 客户端），其他组合可以根据合适的链路做针对性的配置：

* 集群内访问，未开启鉴权认证，走非传输加密
* 集群内访问，开启鉴权认证（TLS 协议），走传输加密
* 集群外访问，开启鉴权认证（SCRAM-SHA-512 协议），走非传输加密
* 集群外访问，开启鉴权认证（SCRAM-SHA-512 协议），走传输加密
* 集群外访问，开启鉴权认证（TLS 协议），走传输加密

---

### 一、集群内访问-未开启鉴权认证，走非传输加密

此时客户端与 Kafka 实例位于同一业务集群，由于 Kafka 服务端未开启鉴权认证，传输过程也无需加密，客户端仅需要获取 Kafka 实例的内部路由即可。

您可以在 【Kafka 实例-访问方式】页签下，复制【集群内访问-Plain 传输的链接地址】，替换到真实的代码片段中。

客户端连接代码示例如下：

```
package com.lanzhiwang.producer;
import java.util.Properties;



import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ExampleProducer {
    public static void main(String[] args) {

        Properties kafkaProps = new Properties();
        kafkaProps.put("bootstrap.servers", "test-kafka-bootstrap:9092");
        kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

       
        // ProducerRecord(String topic, K key, V value)
        ProducerRecord<String, String> record = new ProducerRecord<>("my-cluster-topic", "Precision Products", "China");

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(kafkaProps)) {
            // Ignore the returned value, no way to know the message was sent successfully or not.
            producer.send(record);
            // Thread.sleep(2000000); // 延时 2000 秒
        } catch (Exception e) {
            // If the producer encountered errors before sending the message to Kafka.
            e.printStackTrace();
        }
    }
}
```

### 二、集群内访问-开启鉴权认证（TLS 协议），走传输加密

此时客户端与 Kafka 实例位于同一业务集群，由于 Kafka 服务端开启鉴权认证，传输过程需加密，客户端需要获取 Kafka 实例的内部路由地址、TLS 协议的用户及密码证书以及 TLS 协议的传输证书。

1. Kafka 实例的内部路由地址

    您可以在 【Kafka 实例-访问方式】页签下，复制【集群内访问-TLS 传输的链接地址】，替换到真实的代码片段中。

2. TLS 协议的传输及密码证书

    通过 kubectl 命令，生成用户及密码的证书，并将相关证书拷贝到客户端相关的路径下，具体命令为：

    * 生成 CA 证书：
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 实例名称}-cluster-ca-cert -o jsonpath='{.data.ca\.p12}' | base64 -d > ca.p12
        ```

    * 生成 CA 证书的密码
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 实例名称}-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
        ```

3. TLS 协议的用户及密码证书

    通过 kubectl 命令，生成传输及密码的证书，并将相关证书拷贝到客户端相关的路径下，具体命令为：

    * 生成用户证书：
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.p12}' | base64 -d > user.p12
        ```

    * 生成用户证书的密码：
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.password}' | base64 -d
        ```

4、客户端连接代码示例如下：

```
package com.lanzhiwang.producer;
import java.util.Properties;



import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ExampleProducer {
    public static void main(String[] args) {

        Properties kafkaProps = new Properties();
        kafkaProps.put("bootstrap.servers", "test-kafka-bootstrap:9093");
        kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // Configure TLS/SSL properties
        kafkaProps.put("security.protocol", "SSL");
        // kubectl -n {Kafka 实例所在命名空间} get secret {KafkaClusterName}-cluster-ca-cert -o jsonpath='{.data.ca\.p12}' | base64 -d > ca.p12
        kafkaProps.put("ssl.truststore.location", "/Users/temp/certs/ca.p12");
        // kubectl -n {Kafka 实例所在命名空间} get secret {KafkaClusterName}-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
        kafkaProps.put("ssl.truststore.password", "************");
        // kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.p12}' | base64 -d > user.p12
        kafkaProps.put("ssl.keystore.location", "/Users/temp/certs/user.p12");
        // kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.password}' | base64 -d
        kafkaProps.put("ssl.keystore.password", "************");
        // 集群内访问无需配置，针对nodeport开启tls时配置
        kafkaProps.put("ssl.endpoint.identification.algorithm", "");
        // ProducerRecord(String topic, K key, V value)
        ProducerRecord<String, String> record = new ProducerRecord<>("my-cluster-topic", "Precision Products", "China");

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(kafkaProps)) {
            // Ignore the returned value, no way to know the message was sent successfully or not.
            producer.send(record);
            // Thread.sleep(2000000); // 延时 2000 秒
        } catch (Exception e) {
            // If the producer encountered errors before sending the message to Kafka.
            e.printStackTrace();
        }
    }
}
```

### 三、集群外访问-开启鉴权认证（SCRAM-SHA-512 协议），走非传输加密

此时客户端与 Kafka 实例位于不同业务集群，由于 Kafka 服务端开启鉴权认证，传输过程无需加密，客户端需要获取 Kafka 实例的集群外访问地址、以及 SCRAM-SHA-512 协议下的用户名和密码。

1. 您可以在 【Kafka 实例-访问方式】页签下，复制【集群内访问-Plain 传输的链接地址】，替换到真实的代码片段中。

2. 可以在【Kafka 实例-用户管理】页签下，使用已有的用户，或者新建用户。

3. 客户端连接代码示例如下：

```
package com.lanzhiwang.producer;
import java.util.Properties;



import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ExampleProducer {
    public static void main(String[] args) {

        Properties kafkaProps = new Properties();
        kafkaProps.put("bootstrap.servers", "192.168.176.13:31786,192.168.176.23:30535,192.168.176.27:30219");
        kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // Configure scram-sha-512 properties
        kafkaProps.put("sasl.mechanism", "SCRAM-SHA-512");
        kafkaProps.put("security.protocol", "SASL_PLAINTEXT");
        kafkaProps.put("sasl.jaas.config", "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"*************\" password=\"*************\";");
        // ProducerRecord(String topic, K key, V value)
        ProducerRecord<String, String> record = new ProducerRecord<>("my-cluster-topic", "Precision Products", "China");

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(kafkaProps)) {
            // Ignore the returned value, no way to know the message was sent successfully or not.
            producer.send(record);
            // Thread.sleep(2000000); // 延时 2000 秒
        } catch (Exception e) {
            // If the producer encountered errors before sending the message to Kafka.
            e.printStackTrace();
        }
    }
}
```

### 四、集群外访问-开启鉴权认证（SCRAM-SHA-512 协议），走传输加密

此时客户端与 Kafka 实例位于不同业务集群，由于 Kafka 服务端开启鉴权认证，传输过程需加密，客户端需要获取 Kafka 实例的集群外访问地址、 SCRAM-SHA-512 协议下的用户名和密码，以及 TLS 协议的传输证书。

1. 您可以在 【Kafka 实例-访问方式】页签下，复制【集群内访问-Plain 传输的链接地址】，替换到真实的代码片段中。

2. 可以在【Kafka 实例-用户管理】页签下，使用已有的用户，或者新建用户。

3. TLS 协议的传输及密码证书

    通过 kubectl 命令，生成用户及密码的证书，并将相关证书拷贝到客户端相关的路径下，具体命令为：

    * 生成 CA 证书：
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 实例名称}-cluster-ca-cert -o jsonpath='{.data.ca\.p12}' | base64 -d > ca.p12
        ```

    * 生成 CA 证书的密码
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 实例名称}-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
        ```

4. 客户端连接代码示例如下：

```
package com.lanzhiwang.producer;
import java.util.Properties;



import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ExampleProducer {
    public static void main(String[] args) {

        Properties kafkaProps = new Properties();
        kafkaProps.put("bootstrap.servers", "192.168.176.13:31786,192.168.176.23:30535,192.168.176.27:30219");
        kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        kafkaProps.put("security.protocol", "SASL_SSL");
        kafkaProps.put("sasl.mechanism", "SCRAM-SHA-512");
        kafkaProps.put("ssl.truststore.location", "/Users/temp/certs/ca.p12");
        kafkaProps.put("ssl.truststore.password", "************");
        kafkaProps.put("sasl.jaas.config", "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"*************\" password=\"*************\";");
        // 集群内访问无需配置，针对nodeport开启tls时配置
        kafkaProps.put("ssl.endpoint.identification.algorithm", "");
        // ProducerRecord(String topic, K key, V value)
        ProducerRecord<String, String> record = new ProducerRecord<>("my-cluster-topic", "Precision Products", "China");

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(kafkaProps)) {
            // Ignore the returned value, no way to know the message was sent successfully or not.
            producer.send(record);
            // Thread.sleep(2000000); // 延时 2000 秒
        } catch (Exception e) {
            // If the producer encountered errors before sending the message to Kafka.
            e.printStackTrace();
        }
    }
}
```

### 集群外访问-开启鉴权认证（TLS 协议），走传输加密

此时客户端与 Kafka 实例位于不同业务集群，由于 Kafka 服务端开启鉴权认证，传输过程需加密，客户端需要获取 Kafka 实例的集群外访问地址、 SCRAM-SHA-512 协议下的用户名和密码，以及 TLS 协议的传输证书。

1. 您可以在 【Kafka 实例-访问方式】页签下，复制【集群内访问-Plain 传输的链接地址】，替换到真实的代码片段中。

2. TLS 协议的传输及密码证书

    通过 kubectl 命令，生成用户及密码的证书，并将相关证书拷贝到客户端相关的路径下，具体命令为：

    * 生成 CA 证书：
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 实例名称}-cluster-ca-cert -o jsonpath='{.data.ca\.p12}' | base64 -d > ca.p12
        ```

    * 生成 CA 证书的密码
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 实例名称}-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
        ```

3. TLS 协议的用户及密码证书

    通过 kubectl 命令，生成传输及密码的证书，并将相关证书拷贝到客户端相关的路径下，具体命令为：

    * 生成用户证书：
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.p12}' | base64 -d > user.p12
        ```

    * 生成用户证书的密码：
        ```
        $ kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.password}' | base64 -d
        ```

4. 客户端连接代码示例如下：

```
package com.lanzhiwang.producer;
import java.util.Properties;



import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

public class ExampleProducer {
    public static void main(String[] args) {

        Properties kafkaProps = new Properties();
        kafkaProps.put("bootstrap.servers", "192.168.176.13:31786,192.168.176.23:30535,192.168.176.27:30219");
        kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        // Configure TLS/SSL properties
        kafkaProps.put("security.protocol", "SSL");
        // kubectl -n {Kafka 实例所在命名空间} get secret {KafkaClusterName}-cluster-ca-cert -o jsonpath='{.data.ca\.p12}' | base64 -d > ca.p12
        kafkaProps.put("ssl.truststore.location", "/Users/temp/certs/ca.p12");
        // kubectl -n {Kafka 实例所在命名空间} get secret {KafkaClusterName}-cluster-ca-cert -o jsonpath='{.data.ca\.password}' | base64 -d
        kafkaProps.put("ssl.truststore.password", "************");
        // kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.p12}' | base64 -d > user.p12
        kafkaProps.put("ssl.keystore.location", "/Users/temp/certs/user.p12");
        // kubectl -n {Kafka 实例所在命名空间} get secret {Kafka 用户名称} -o jsonpath='{.data.user\.password}' | base64 -d
        kafkaProps.put("ssl.keystore.password", "************");
        // 集群内访问无需配置，针对nodeport开启tls时配置
        kafkaProps.put("ssl.endpoint.identification.algorithm", "");
        // ProducerRecord(String topic, K key, V value)
        ProducerRecord<String, String> record = new ProducerRecord<>("my-cluster-topic", "Precision Products", "China");

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(kafkaProps)) {
            // Ignore the returned value, no way to know the message was sent successfully or not.
            producer.send(record);
            // Thread.sleep(2000000); // 延时 2000 秒
        } catch (Exception e) {
            // If the producer encountered errors before sending the message to Kafka.
            e.printStackTrace();
        }
    }
}
```